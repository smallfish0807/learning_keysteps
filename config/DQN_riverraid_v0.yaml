env: RiverraidNoFrameskip-v0
GPU: 0
algorithm: DQN
model:
    atari: True
    exploration:
        name: epsilon_greedy
        epsilon_end: 0.01
        epsilon_decay: 250000
        epsilon_test: 0.001
common:
    seed: 1126
    batch_size: 32
    gamma: 0.99
    lr: 0.0001
    training_steps: 200000000
    target_update_freq: 1000
    learn_start: 20000
    learn_freq: 4
    replay_buffer: 100000
    test_freq: 100000
    test_num: 10
    max_steps_per_episode: 27000
